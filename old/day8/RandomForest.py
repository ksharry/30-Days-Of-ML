import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

def main():
    print("ğŸš€ Day 8: éš¨æ©Ÿæ£®æ— (Random Forest) å•Ÿå‹•...")

    # --- 1. è¼‰å…¥è³‡æ–™ ---
    filename = 'german_credit_data.csv'
    try:
        # å˜—è©¦è®€å–ï¼Œè™•ç†åˆ†éš”ç¬¦è™Ÿå•é¡Œ
        df = pd.read_csv(filename, sep='\t')
        if len(df.columns) < 5: 
            df = pd.read_csv(filename, sep=',')
        print(f"âœ… è³‡æ–™è¼‰å…¥æˆåŠŸï¼è³‡æ–™å¤§å°: {df.shape}")
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼Œè«‹ç¢ºèªè·¯å¾‘æ˜¯å¦æ­£ç¢ºã€‚")
        return

    # --- 2. è³‡æ–™å‰è™•ç† ---
    # 2.1 è™•ç† Target
    if 'class' in df.columns:
        target_col = 'class'
    else:
        target_col = df.columns[-1]

    # è½‰æˆ 0 (Good) å’Œ 1 (Bad/Risk)
    if df[target_col].dtype == 'object':
        df['target'] = df[target_col].map({'bad': 1, 'good': 0})
    else:
        df['target'] = df[target_col]
    
    if target_col != 'target':
        df = df.drop(columns=[target_col])

    # 2.2 ç‰¹å¾µç·¨ç¢¼ (Label Encoding)
    # éš¨æ©Ÿæ£®æ—é›–ç„¶å¼·å¤§ï¼Œä½† sklearn ç‰ˆæœ¬ä»å»ºè­°å°‡æ–‡å­—è½‰æ•¸å­—
    for col in df.columns:
        if col == 'target': continue
        if df[col].dtype == 'object' or df[col].dtype.name == 'category':
            le = LabelEncoder()
            df[col] = le.fit_transform(df[col].astype(str))

    # --- 3. åˆ‡åˆ†è³‡æ–™ ---
    X = df.drop('target', axis=1)
    y = df['target']
    X = X.fillna(0) # ç°¡æ˜“è£œå€¼

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42
    )

    # --- 4. å»ºç«‹ä¸¦è¨“ç·´éš¨æ©Ÿæ£®æ— ---
    print("ğŸŒ² æ­£åœ¨ç¨®æ¤ 100 æ£µæ±ºç­–æ¨¹ (Training)...")
    # n_estimators=100: ç¨® 100 æ£µæ¨¹
    # max_depth=None: ä¸é™åˆ¶æ·±åº¦ï¼Œè®“æ¨¹è‡ªç”±ç”Ÿé•· (éš¨æ©Ÿæ£®æ—ä¸æ€•éæ“¬åˆ)
    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
    rf_model.fit(X_train, y_train)

    # --- 5. è©•ä¼°èˆ‡è¦–è¦ºåŒ– ---
    # 5.1 æº–ç¢ºç‡æ¯”è¼ƒ (Overfitting Check)
    train_acc = rf_model.score(X_train, y_train)
    print(f"\nğŸ¯ è¨“ç·´é›†æº–ç¢ºç‡ (Training Acc): {train_acc:.2f}")

    y_pred = rf_model.predict(X_test)
    test_acc = accuracy_score(y_test, y_pred)
    print(f"ğŸ† æ¸¬è©¦é›†æº–ç¢ºç‡ (Test Acc):     {test_acc:.2f}")
    
    # è¨­å®šç•«å¸ƒ
    plt.figure(figsize=(14, 6))
    
    # [å·¦åœ–] æ··æ·†çŸ©é™£
    plt.subplot(1, 2, 1)
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', 
                xticklabels=['Good', 'Bad'], yticklabels=['Good', 'Bad'])
    plt.title('Confusion Matrix (Prediction Accuracy)')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')

    # [å³åœ–] ç‰¹å¾µé‡è¦æ€§ (Feature Importance)
    plt.subplot(1, 2, 2)
    importances = rf_model.feature_importances_
    # æ’åºå–å¾—å‰ 10 å
    indices = np.argsort(importances)[::-1]
    top_n = 10
    
    plt.title('Top 10 Key Features (What matters most?)')
    plt.barh(range(top_n), importances[indices[:top_n]][::-1], color='forestgreen', align='center')
    plt.yticks(range(top_n), X.columns[indices[:top_n]][::-1])
    plt.xlabel('Importance Score')
    
    plt.tight_layout()
    plt.show()
    print("âœ… åˆ†æå®Œæˆï¼å³åœ–é¡¯ç¤ºäº†å½±éŸ¿ä¿¡ç”¨è©•åˆ†æœ€é—œéµçš„å› ç´ ã€‚")

if __name__ == "__main__":
    main()