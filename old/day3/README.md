# Day 03：正則化回歸 (Ridge & Lasso) —— 馴服脫韁野馬

## 0. 歷史小故事：奧卡姆剃刀 (Occam's Razor)

在深入複雜的數學公式前，我們先回到 14 世紀。英格蘭邏輯學家 **威廉·奧卡姆 (William of Ockham)** 提出了一個影響後世深遠的哲學原則：

> **"Entities should not be multiplied without necessity."**
> （若無必要，勿增實體。）

這就是著名的 **「奧卡姆剃刀」** 原則。它的核心思想很簡單：在解釋同一個現象時，越簡單的理論通常越好，越不容易出錯。

到了現代機器學習領域，這個原則演變成了 **「正則化」 (Regularization)**。當我們的模型為了追求完美的訓練分數，變得過度複雜（像是背誦答案的學生）時，我們需要一把「剃刀」來修剪它，強制它保持簡單。這把數學上的剃刀，就是我們今天要介紹的 **Ridge (L2)** 與 **Lasso (L1)**。

---
## 1. 資料集來源
本實作使用 Scikit-Learn 內建的 [California Housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) 資料集。

---
## 2. 理論

在 Day 02 中，我們遇到了「低度擬合 (Underfitting)」的問題。假設我們為了提高分數，瘋狂增加特徵（例如加入 $x^2, x^3, \dots, x^{10}$），模型可能會變得極度扭曲以穿過每一個訓練數據點，這就導致了 **「過度擬合」 (Overfitting)**。

### 什麼是正則化？

正則化的本質，是在原本的 **損失函數 (Loss Function)** 後面加上一個 **「懲罰項」 (Penalty Term)**。這就像是老師告訴學生：「考一百分雖然好，但如果你用死記硬背的方式（模型參數 $w$ 太大或太複雜），我要扣你分數。」

新的損失函數公式如下：

$$J(\text{total}) = \text{MSE (原本的誤差)} + \alpha \times \text{Penalty (複雜度懲罰)}$$

其中 $\alpha$ (Alpha) 是一個超參數，用來控制懲罰的力度：
* $\alpha = 0$：就是一般的線性回歸。
* $\alpha$ 越大：懲罰越重，模型越簡單（趨向水平線）。

### Ridge Regression (脊回歸 / L2 正則化)

Ridge 使用 **權重的平方和** 作為懲罰項。

$$J(w) = \text{MSE} + \alpha \sum_{j=1}^{n} w_j^2$$

* **數學特性：** 由於平方的特性，它會讓權重 $w$ 變得 **很小**，趨近於 0，但 **不會等於 0**。
* **幾何意義：** 想像一個圓形限制區域。Ridge 傾向於均勻地縮小所有參數。
* **優點：** 非常適合處理 **共線性 (Multicollinearity)** 問題（即特徵之間高度相關，如「房間數」與「臥室數」）。

### Lasso Regression (套索回歸 / L1 正則化)

Lasso (Least Absolute Shrinkage and Selection Operator) 使用 **權重的絕對值和** 作為懲罰項。

$$J(w) = \text{MSE} + \alpha \sum_{j=1}^{n} |w_j|$$

* **數學特性：** 這是 Lasso 最迷人的地方。它有能力把不重要的特徵權重 **直接壓縮為 0**。
* **幾何意義：** L1 的限制區域是 **菱形 (Diamond shape)**。當誤差函數的等高線接觸到菱形的「尖角」時，該維度的係數就會變成 0。
* **優點：** 內建 **特徵選擇 (Feature Selection)** 功能。如果你有 1000 個特徵但只有 10 個有用，Lasso 會自動幫你挑出來。

*(Lasso 的菱形限制區域容易讓解落在軸上，使係數變為 0；Ridge 的圓形區域則傾向讓係數變小。)*

### L1 vs L2 比較表

| 特性 | Ridge (L2) | Lasso (L1) |
| :--- | :--- | :--- |
| **懲罰項** | $\sum w^2$ (平方) | $\sum \|w\|$ (絕對值) |
| **權重變化** | 變得很小 (接近 0) | 可以變成 0 (稀疏解) |
| **幾何形狀** | 圓球 (Ball) | 菱形 (Diamond) |
| **主要功能** | 防止過擬合、處理共線性 | 防止過擬合、特徵篩選 |

---

## 3. 實戰：加州房價預測
### Python 程式碼實作

完整程式連結：[Regularization_Demo.py](https://github.com/ksharry/30-Days-Of-ML/blob/main/day3/Regularization_Demo.py)

## 4. 模型評估

### 整體成績單
* 🔹 **測試集準確率 (Test Acc): 0.88** 


### **實驗設定 (`Regularization_Demo.py`)：**
為了演示正則化的威力，我們這次不能只用簡單的線性資料。我們需要先 **「製造過擬合」**。

1.  **多項式擴充 (Polynomial Features)：** 將原本的加州房價資料特徵進行 3 次方擴充。這會讓特徵數量從原本的 8 個暴增到 **164 個**（包含 $x^2, x^3$ 及交互作用項）。這就像給模型裝上了一顆過大的引擎。
2.  **減少數據量：** 故意只取 200 筆資料，製造「題目少、變數多」的高風險環境。
3.  **標準化 (Standardization)：** 務必將資料縮放至同一尺度，以免數值大的特徵被不公平地懲罰。

#### 偏差與變異權衡 (Bias-Variance Tradeoff)
![Bias-Variance Tradeoff](https://github.com/ksharry/30-Days-Of-ML/blob/main/day3/pic/3-1.jpg?raw=true)
* **觀察現象：**
    * **Linear (No Reg - 最左側)：** 典型的過度擬合。訓練集分數 (藍色) 高達 1.0 (死記硬背)，但測試集分數 (橘色) 卻是 **負值** (徹底崩潰)。
    * **Ridge (L2) 與 Lasso (L1)：** 雖然訓練集分數稍微下降 (約 0.75)，但測試集分數大幅回升至 0.8 以上。
* **解讀：**
    正則化強迫模型「不要那麼極端」。雖然犧牲了一點點訓練準度（Bias 略微增加），但換來了模型在未知資料上的穩定表現（Variance 大幅降低）。

#### 權重係數的收縮與稀疏性
![Ridge vs Lasso](https://github.com/ksharry/30-Days-Of-ML/blob/main/day3/pic/3-2.jpg?raw=true)
* **觀察現象：**
    * **Ridge (L2, 藍色圓點)：** 藍點分布在 0 的上下，雖然數值都被壓縮得很小，但幾乎沒有一個點完全等於 0。
    * **Lasso (L1, 紅色三角形)：** 絕大多數的紅色三角形都直接躺在 0 上，只有少數幾個特徵突出。
* **解讀：**
    這張圖證實了 Lasso (L1) 具備「特徵選擇」能力，將不重要的雜訊權重直接砍成 0；而 Ridge (L2) 則是做「權重衰減」，保留所有資訊但讓模型變平滑。

---
### 深度分析：Lasso (L1) 的大刀闊斧
我們在 `Regularization_L1.py` 中針對 Alpha 進行了深度調參。
![Lasso](https://github.com/ksharry/30-Days-Of-ML/blob/main/day3/pic/3-3.jpg?raw=true)
**實驗結果**
* **最佳 Alpha:** 0.00085
* **保留特徵數:** 46 / 164
* **Test R2 Score:** 0.8838

**為什麼只剩下 46 個特徵？**
這 46 個是從 164 個擴充特徵中「精簡」後的倖存者（砍掉了約 70%）。
圖表顯示，當 Alpha 極小時（左側），模型保留了 100 多個特徵，導致過擬合；當 Alpha 調整到最佳點時，Lasso 認為：「為了維持 0.88 這麼高的分數，這 46 個特徵是必須留下的，其他的都是雜訊。」

**結論：** Lasso 像一位精準的外科醫生，切除掉 100 多個壞特徵，只保留關鍵組合，成功將分數救回 0.88。

---
### 深度分析：Ridge (L2) 的穩健收縮

我們在 `Regularization_L2.py` 中觀察係數的變化。
![Ridge](https://github.com/ksharry/30-Days-Of-ML/blob/main/day3/pic/3-4.jpg?raw=true)
**實驗結果**
* **最佳 Alpha:** 0.14175
* **被視為 0 的特徵數:** 0 (全部保留)
* **Test R2 Score:** 0.8752

**核心差異**
L2 的圖表亮點不在於特徵數量的減少，而在於 **「平均係數大小 (Average Coefficient Magnitude)」** 的下滑。
隨著 Alpha 增加（往右移動），紅線快速下滑，這代表 L2 正在強力壓縮那些原本暴衝到幾百幾千的係數，將它們壓制在合理的範圍內 (如 0.5, -0.2)，從而修復了模型的穩定性。

---

### 終極挑戰：ElasticNet 與天花板

既然 L1 和 L2 各有千秋，我們使用 ElasticNet (`Regularization_EL.py`) 來尋找最佳混合比例。
![ElasticNet](https://github.com/ksharry/30-Days-Of-ML/blob/main/day3/pic/3-5.jpg?raw=true)
**1. 熱力圖解密：尋找「黃金高原」**
這張熱力圖呈現了大片的黃色區域（高分區）。
* **意義：** 這意味著只要懲罰力道 (Alpha) 控制得當，不管你是偏向 L1 還是 L2，結果都差不多。這個模型在經過特徵擴充後非常「穩健 (Robust)」。
* **危險區 (紫色)：** 右上角（Alpha 大 + L1 Ratio 大）。代表懲罰太重且硬要砍特徵，導致模型崩潰 (Underfitting)。

**2. 為什麼分數卡在 0.88？**
無論怎麼調參，分數似乎都停在 0.88 左右。這揭示了機器學習的一個核心概念：**貝氏誤差 (Bayes Error)**。
這 200 筆資料裡蘊含的資訊極限，最多只能解釋 88% 的房價波動。剩下的 12% 是隨機雜訊或未收集到的變因，這是任何線性模型都無法突破的天花板。


## 5. 戰略總結:模型訓練的火箭發射之旅

最後，讓我們引用 AI 大師 **吳恩達 (Andrew Ng)** 的經典圖表，來重新審視我們如何在 Day 03 中調整 Ridge 和 Lasso 的 $\alpha$ 參數，完成這次的發射任務。

![Model Training and Tuning Process](https://github.com/ksharry/30-Days-Of-ML/blob/main/day2/pic/2-6.jpg?raw=true)

在 Day 03 的實驗中，我們為了預測房價，使用多項式特徵 ($x^3$) 擴充了資料。這就像是我們安裝了一個 **超級強力的火箭引擎**（模型變得很複雜）。現在，我們需要透過調整 $\alpha$ (正則化強度) 來控制這枚火箭。

### 5.1 流程一：動力太強，失控墜毀 (Overfitting 迴圈)

* **設定**：我們將 $\alpha$ 設為 **0** (也就是 Linear Regression)。
* **第一關：訓練集表現好嗎？**
    * **是 (Yes)**。因為引擎馬力全開，訓練分數高達 1.0 (滿分)。
* **第二關：測試集表現好嗎？**
    * **否 (No)**。測試分數是負的 (崩潰)。
    * **診斷**：**過擬合 (Overfitting)**。火箭雖然飛起來了，但因為動力太強且沒有控制系統，在空中亂飛最後解體。
* **行動 (Action)**：箭頭指向 **「調整參數：增加正則化」**。
    * **操作**：我們開始 **增加 $\alpha$ 值** (例如從 0 變成 0.001)。這就像是幫火箭裝上 **「穩定翼」或「自動煞車系統」**，限制權重 $w$ 不要暴衝。

### 5.2 流程二：煞車踩死，無法升空 (Underfitting 迴圈)

* **設定**：我們試著將 $\alpha$ 設得很大 (例如 $\alpha = 100$)。
* **第一關：訓練集表現好嗎？**
    * **否 (No)**。
    * **診斷**：**欠擬合 (Underfitting)**。因為懲罰太重，所有的權重 $w$ 都被壓縮成接近 0。這就像火箭引擎雖然大，但我們卻把燃料管捏死（或是煞車踩死），導致火箭根本推不動，連訓練分數都很低。
* **行動 (Action)**：箭頭指向 **「調整參數：減少限制」**。
    * **操作**：我們需要 **減小 $\alpha$ 值**，放鬆懲罰，讓模型多學一點特徵。

### 5.3 流程三：完美入軌 (The Sweet Spot)

* **設定**：經過反覆測試，我們找到了 **$\alpha = 0.00085$** (Lasso 的最佳解)。
* **第一關：訓練集表現好嗎？**
    * **是** (約 0.88)。雖然沒有 1.0 那麼高，但已經很不錯了。
* **第二關：測試集表現好嗎？**
    * **是** (約 0.88)。模型在未知的資料上也能穩定飛行。
* **結果**：**完成！** 火箭成功入軌。

---

## 6. 總結與比較

### 6.1 Day 02 vs Day 03：引擎與剎車

讓我們用「引擎比喻」來對照這兩天的學習：

| 比較項目 | Day 02 (Linear) | Day 03 (Regularization) |
| :--- | :--- | :--- |
| **問題診斷** | **High Bias (高偏差)**<br>馬力不足，跑不快。 | **High Variance (高變異)**<br>引擎太大，車子失控。 |
| **解決方案** | 需要「更大的引擎」。 | 加裝 **Turbo (多項式擴充)** <br>+ **ABS煞車系統 (L1/L2)**。 |
| **數據量** | 認為增加數據沒用。 | **只用 200 筆** 也能跑出高分。 |
| **R2 分數** | 卡在 0.6 天花板。 | **突破至 0.88**。 |

**結論：** 我們成功驗證了 Day 02 的推論。問題不在數據量，而在於模型複雜度。一旦換了複雜模型（大引擎）並配合正則化（好煞車），分數馬上爆發。

### 6.2 該選 L1 還是 L2？(診斷指南)

| 選擇 | 適用情境 | 你的資料長怎樣？ |
| :--- | :--- | :--- |
| **Lasso (L1)** | 特徵選擇 | **稀疏 (Sparse)**：只有少數特徵是關鍵的，其他都是雜訊。 |
| **Ridge (L2)** | 處理共線性 | **稠密 (Dense)**：大部分特徵都有一點貢獻，且特徵間高度相關。 |
| **ElasticNet** | 不確定時 | 混合型資料，或者是你想買個保險時的首選。 |

---

### Next Step:
Day 03 我們學會了如何預測「連續數值」。但如果我們想預測的是「是/否」或「類別」呢？

**Day 04 - 邏輯回歸 (Logistic Regression)** 將登場。雖然名字裡有「回歸」，但它卻是最經典的 **分類演算法**。我們將探討 Sigmoid 函數如何將線性直線彎曲成 S 型曲線，來進行機率分類。