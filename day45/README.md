# Day 45: 深入理解 CNN 架構 - 以 VGG16 為例 (Deep Dive into VGG16 Architecture)

## 0. 前言
在 Day 25 和 Day 26，我們學習了 CNN 和遷移學習，並使用了 VGG16 這個經典模型。
但你是否曾經看著 `model.summary()` 或 `torchsummary` 輸出的那一長串表格，感到一頭霧水？
*   為什麼圖片大小會變？
*   為什麼參數有時候是 0，有時候是一億？
*   為什麼通道數 (Channels) 要一直變大？

今天我們不跑訓練，而是要像「解剖學」一樣，把 VGG16 切開來，一行一行看懂它到底在做什麼。

## 1. 實戰程式碼
我們先用 `torchsummary` 把 VGG16 的架構印出來。

### Python 程式碼實作
完整程式連結：[VGG16_Summary.py](VGG16_Summary.py)

```python
from torchsummary import summary
from torchvision import models

# 載入 VGG16 (使用 ImageNet 預訓練權重)
model = models.vgg16(weights='IMAGENET1K_V1')

# 顯示摘要 (假設輸入圖片大小為 150x150)
summary(model, (3, 150, 150))
```

## 2. 讀懂 Summary 表格
當你執行上面的程式，會看到類似這樣的輸出 (截取部分)：

```text
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 150, 150]           1,792
              ReLU-2         [-1, 64, 150, 150]               0
            Conv2d-3         [-1, 64, 150, 150]          36,928
              ReLU-4         [-1, 64, 150, 150]               0
         MaxPool2d-5           [-1, 64, 75, 75]               0
            Conv2d-6          [-1, 128, 75, 75]          73,856
              ReLU-7          [-1, 128, 75, 75]               0
            Conv2d-8          [-1, 128, 75, 75]         147,584
              ReLU-9          [-1, 128, 75, 75]               0
        MaxPool2d-10          [-1, 128, 37, 37]               0
           Conv2d-11          [-1, 256, 37, 37]         295,168
             ReLU-12          [-1, 256, 37, 37]               0
           Conv2d-13          [-1, 256, 37, 37]         590,080
             ReLU-14          [-1, 256, 37, 37]               0
           Conv2d-15          [-1, 256, 37, 37]         590,080
             ReLU-16          [-1, 256, 37, 37]               0
        MaxPool2d-17          [-1, 256, 18, 18]               0
           Conv2d-18          [-1, 512, 18, 18]       1,180,160
             ReLU-19          [-1, 512, 18, 18]               0
           Conv2d-20          [-1, 512, 18, 18]       2,359,808
             ReLU-21          [-1, 512, 18, 18]               0
           Conv2d-22          [-1, 512, 18, 18]       2,359,808
             ReLU-23          [-1, 512, 18, 18]               0
        MaxPool2d-24            [-1, 512, 9, 9]               0
           Conv2d-25            [-1, 512, 9, 9]       2,359,808
             ReLU-26            [-1, 512, 9, 9]               0
           Conv2d-27            [-1, 512, 9, 9]       2,359,808
             ReLU-28            [-1, 512, 9, 9]               0
           Conv2d-29            [-1, 512, 9, 9]       2,359,808
             ReLU-30            [-1, 512, 9, 9]               0
        MaxPool2d-31            [-1, 512, 4, 4]               0
AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0
           Linear-33                 [-1, 4096]     102,764,544
             ReLU-34                 [-1, 4096]               0
          Dropout-35                 [-1, 4096]               0
           Linear-36                 [-1, 4096]      16,781,312
             ReLU-37                 [-1, 4096]               0
          Dropout-38                 [-1, 4096]               0
           Linear-39                 [-1, 1000]       4,097,000
================================================================
Total params: 138,357,544
Trainable params: 138,357,544
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.26
Forward/backward pass size (MB): 96.93
Params size (MB): 527.79
Estimated Total Size (MB): 624.98
----------------------------------------------------------------
```

這張表有三個關鍵欄位，我們一個一個來看：

### 2.1 Layer (type) - 這一層是誰？
*   **Conv2d**: 卷積層。負責「看」特徵 (提取線條、形狀)。
*   **ReLU**: 激活函數。負責把負數歸零 (增加非線性)，不改變形狀。
*   **MaxPool2d**: 池化層。負責「縮圖」 (取最大值)，減少運算量。
*   **Linear**: 全連接層。負責「分類」 (綜合判斷)。

### 2.2 Output Shape - 尺寸變化全解析
格式通常是 `[-1, Channel, Height, Width]`。
*   **-1 (Batch Size)**: 代表一次丟幾張圖都可以 (不固定)。
*   **Channel (通道數)**: 特徵圖的數量 (濾鏡數)。
*   **Height, Width (長寬)**: 特徵圖的尺寸。

#### 為什麼圖片大小一直變？ (150 -> 4 -> 7)
這是一個非常有趣的過程，我們追蹤 `Height/Width` 的變化：
1.  **150x150 -> 75x75** (`MaxPool2d-5`)：
    *   池化層除以 2。
2.  **75x75 -> 37x37** (`MaxPool2d-10`)：
    *   75 / 2 = 37.5。電腦無條件捨去，變成 37。
3.  **37x37 -> 18x18** (`MaxPool2d-17`)：
    *   37 / 2 = 18.5。無條件捨去，變成 18。
4.  **18x18 -> 9x9** (`MaxPool2d-24`)：
    *   除以 2。
5.  **9x9 -> 4x4** (`MaxPool2d-31`)：
    *   9 / 2 = 4.5。無條件捨去，變成 4。
6.  **4x4 -> 7x7** (`AdaptiveAvgPool2d-32`)：
    *   **神奇的一步！** 前面一路縮小到 4x4，但 VGG16 為了要接上固定的全連接層，強制把特徵圖「拉」回 7x7 的大小。這就是 `Adaptive` (自適應) 的功能。

#### 為什麼通道數一直變大？ (64 -> 128 -> 256 -> 512)
*   **設計哲學**：當圖片變小 (75x75) 時，運算量變小了，所以我們可以「奢侈」一點，用更多種濾鏡 (64 -> 128) 來抓更多樣化的特徵。
*   **比喻**：
    *   **大圖 (150x150)**：像在看海報，只能粗略看線條 (64種特徵)。
    *   **小圖 (75x75)**：像在看明信片，可以拿放大鏡仔細看細節 (128種特徵)。

### 2.3 Param # - 參數有多少？
這是模型「腦容量」的大小，也是訓練時要調整的數字。

#### 1. 為什麼 ReLU 和 MaxPool 是 0？
*   因為它們只是執行固定的數學規則 (取正數、取最大值)，**不需要學習**任何東西，所以參數是 0。

#### 2. Conv2d 參數怎麼算？ (以 Conv2d-1 為例)
*   **公式**：`輸出通道 * (輸入通道 * 卷積核大小 + bias)`
*   **計算**：
    *   輸入：3 (RGB)
    *   輸出：64
    *   卷積核：3x3 (VGG 標準)
    *   Bias：每個輸出通道 1 個
    *   `64 * (3 * 3 * 3 + 1) = 64 * 28 = 1,792`
*   **結論**：完全吻合！

#### 3. Linear 參數為什麼爆炸大？ (以 Linear-33 為例)
這是 VGG16 最肥大的一層，佔了絕大多數的容量。
*   **輸入在哪？**
    *   在進入 Linear 之前，特徵圖會被 **Flatten (攤平)**。
    *   VGG 最後的特徵圖大小是 `512 * 7 * 7` (經過多次 MaxPool)。
    *   `512 * 7 * 7 = 25,088` (這就是輸入長度)。
*   **公式**：`輸入特徵 * 輸出特徵 + bias`
*   **計算**：
    *   輸入：25,088
    *   輸出：4,096 (VGG 設計)
    *   `25,088 * 4,096 + 4,096 = 102,760,448 + 4,096 = 102,764,544`
*   **結論**：一億多個參數！這就是為什麼 VGG16 檔案這麼大 (500MB+) 的主因。

## 3. 深度問答 (Q&A)

### Q1: 為什麼要一直把圖縮小 (Pooling)？
*   **省資源**：如果不縮小，參數量和運算量會大到跑不動。
*   **抓重點**：縮小後的圖片保留的是「最顯著」的特徵 (Max Pooling)，去除了雜訊。
*   **擴大視野 (Receptive Field)**：在小圖上的 `3x3`，對應回原圖可能是一個很大的區域。這讓後面的層能看到「整隻貓」，而不只是「貓毛」。

### Q2: 為什麼 Linear 層參數這麼多，還要這樣設計？
*   這是早期的設計 (2014年)。
*   全連接層 (Linear) 的目的是把前面提取到的所有特徵 (25088個)，做一次**全域的綜合判斷**。
*   雖然參數多且容易 Overfitting，但它提供了強大的分類能力。
*   *註：現代模型 (如 ResNet, EfficientNet) 多改用 **Global Average Pooling** 來取代巨大的 Linear 層，大幅減少了參數量。*

### Q3: [-1, 4096] 是最後的結果嗎？
*   不是。這只是「特徵向量」。
*   你可以把它想像成模型對這張圖片寫的 **4096 字摘要**。
*   真正的分類結果在最後一層 `Linear-39`，輸出 `[-1, 1000]` (ImageNet 的 1000 類)，然後接 Softmax 變成機率。

## 4. 總結
Day 45 我們像法醫一樣解剖了 VGG16。
*   **Conv2d**：參數少，運算重 (掃描整張圖)。
*   **Linear**：參數多，運算輕 (矩陣乘法)。
*   **結構美學**：圖越小，通道越多 (用更多視角看抽象特徵)。
*   **數字的秘密**：`150 -> 75` 是因為 Pooling；`1億參數` 是因為 Flatten 後的暴力全連接。

看懂了這張表，以後看到任何新的模型 (ResNet, MobileNet)，你都能一眼看穿它的底細！
