# Day 26: é·ç§»å­¸ç¿’ (Transfer Learning) - ç«™åœ¨å·¨äººçš„è‚©è†€ä¸Š
# ---------------------------------------------------------
# æ˜¨å¤©æˆ‘å€‘è‡ªå·±è¨“ç·´ CNNï¼Œæº–ç¢ºç‡ç´„ 75%ã€‚
# ä»Šå¤©æˆ‘å€‘è¦ä½¿ç”¨ "é·ç§»å­¸ç¿’"ï¼Œç›´æ¥æ‹¿ Google/Microsoft è¨“ç·´å¥½çš„è¶…å¼·æ¨¡å‹ (VGG16) ä¾†ç”¨ã€‚
# VGG16 å·²ç¶“åœ¨ ImageNet (1000 è¬å¼µåœ–ï¼Œ1000 é¡) ä¸Šè¨“ç·´éäº†ï¼Œå®ƒå·²ç¶“ã€Œå­¸æœƒçœ‹åœ–ã€äº†ã€‚
# æˆ‘å€‘åªè¦æŠŠå®ƒçš„ã€Œè…¦è¢‹ (å·ç©å±¤)ã€å€Ÿä¾†ç”¨ï¼Œæ›ä¸Šæˆ‘å€‘è‡ªå·±çš„ã€Œçœ¼ç› (åˆ†é¡å±¤)ã€å³å¯ã€‚
# ---------------------------------------------------------

import numpy as np
import matplotlib.pyplot as plt
import os
import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Flatten, Dropout, Input
from tensorflow.keras.applications import VGG16
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical

# --- 1. æº–å‚™è³‡æ–™ (Data Preparation) ---
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
pic_dir = os.path.join(SCRIPT_DIR, 'pic')
os.makedirs(pic_dir, exist_ok=True)

print("Loading CIFAR-10 Dataset...")
# é€™æ¬¡æˆ‘å€‘æŒ‘æˆ°é›£ä¸€é»çš„ï¼šCIFAR-10 å…¨éƒ¨ 10 é¡ï¼
(X_train, y_train), (X_test, y_test) = cifar10.load_data()

# å–æ¨£ï¼šç‚ºäº†ç¤ºç¯„é€Ÿåº¦ï¼Œæˆ‘å€‘åªå–å‰ 2000 ç­†è¨“ç·´è³‡æ–™ï¼Œ500 ç­†æ¸¬è©¦è³‡æ–™
# é€™æ›´èƒ½å‡¸é¡¯é·ç§»å­¸ç¿’çš„å¨åŠ›ï¼šè³‡æ–™å°‘ä¹Ÿèƒ½è¨“ç·´å¾—å¾ˆå¥½ï¼
train_size = 2000
test_size = 500
X_train, y_train = X_train[:train_size], y_train[:train_size]
X_test, y_test = X_test[:test_size], y_test[:test_size]

# æ­£è¦åŒ– (Normalization)
X_train = X_train / 255.0
X_test = X_test / 255.0

# One-hot Encoding
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

print(f"Train shape: {X_train.shape}")
print(f"Test shape: {X_test.shape}")

# --- 2. è¼‰å…¥é è¨“ç·´æ¨¡å‹ (Load Pre-trained VGG16) ---
print("\nLoading VGG16 Model...")
# include_top=False: ä¸è¦ VGG16 åŸæœ¬çš„åˆ†é¡å±¤ (å› ç‚ºå®ƒæ˜¯åˆ† 1000 é¡ï¼Œæˆ‘å€‘è¦åˆ† 10 é¡)
# input_shape=(32, 32, 3): é…åˆ CIFAR-10 çš„åœ–ç‰‡å¤§å°
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))

# å‡çµ (Freeze) å·ç©å±¤ï¼šä¸è®“å®ƒå€‘æ›´æ–°æ¬Šé‡ï¼Œå› ç‚ºå®ƒå€‘å·²ç¶“å­¸å¾—å¾ˆå¥½äº†
for layer in base_model.layers:
    layer.trainable = False

base_model.summary()

# --- 3. å»ºç«‹æ–°æ¨¡å‹ (Build New Model) ---
# æ¥ä¸Šæˆ‘å€‘è‡ªå·±çš„åˆ†é¡å±¤
x = base_model.output
x = Flatten()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x) # é˜²æ­¢éæ“¬åˆ
predictions = Dense(10, activation='softmax')(x) # 10 é¡è¼¸å‡º

model = Model(inputs=base_model.input, outputs=predictions)

model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

print("\nNew Model Summary:")
# model.summary() # è¼¸å‡ºæœƒå¾ˆé•·ï¼Œå…ˆè¨»è§£æ‰

# --- 4. è¨“ç·´æ¨¡å‹ (Training) ---
print("\nTraining Transfer Learning Model...")
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)
print("Training complete.")

# --- 5. æ¨¡å‹è©•ä¼°èˆ‡è¦–è¦ºåŒ– ---
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"\nTest Accuracy: {test_acc:.4f}")

# è¦–è¦ºåŒ– 1: è¨“ç·´éç¨‹
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss History')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Accuracy History')
plt.legend()
plt.grid(True)
plt.savefig(os.path.join(pic_dir, '26-1_Training_History.png'))
print("Training History plot saved.")

# è¦–è¦ºåŒ– 2: é æ¸¬çµæœå±•ç¤º
class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 
               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']

indices = np.random.choice(len(X_test), 15, replace=False)
images = X_test[indices]
true_labels = np.argmax(y_test[indices], axis=1)
predictions = model.predict(images)
predicted_labels = np.argmax(predictions, axis=1)

plt.figure(figsize=(15, 6))
for i in range(15):
    plt.subplot(3, 5, i + 1)
    plt.imshow(images[i])
    
    color = 'green' if predicted_labels[i] == true_labels[i] else 'red'
    label_text = f"Pred: {class_names[predicted_labels[i]]}\nTrue: {class_names[true_labels[i]]}"
    
    plt.title(label_text, color=color, fontsize=10)
    plt.axis('off')

plt.tight_layout()
plt.savefig(os.path.join(pic_dir, '26-2_Predictions.png'))
print("Predictions plot saved.")

# è¦–è¦ºåŒ– 3: é·ç§»å­¸ç¿’æ¦‚å¿µåœ– (Transfer Learning Concept)
def plot_transfer_learning_concept():
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.axis('off')
    
    # Pre-trained Model (VGG16) - Locked
    rect_vgg = plt.Rectangle((0.1, 0.3), 0.4, 0.4, fc='#FFCC99', ec='black', lw=2)
    ax.add_patch(rect_vgg)
    ax.text(0.3, 0.5, "Pre-trained Model\n(VGG16)\n\nLOCKED ğŸ”’", ha='center', va='center', fontweight='bold')
    ax.text(0.3, 0.25, "Extract Features", ha='center', fontsize=10)

    # Arrow
    ax.arrow(0.5, 0.5, 0.1, 0, head_width=0.05, head_length=0.05, fc='k', ec='k')

    # New Classifier - Trainable
    rect_new = plt.Rectangle((0.65, 0.3), 0.25, 0.4, fc='#99CCFF', ec='black', lw=2)
    ax.add_patch(rect_new)
    ax.text(0.775, 0.5, "New Classifier\n(Dense Layers)\n\nTRAINABLE âœï¸", ha='center', va='center', fontweight='bold')
    ax.text(0.775, 0.25, "Classify 10 Classes", ha='center', fontsize=10)
    
    plt.title("Transfer Learning: Don't Reinvent the Wheel", y=0.9)
    plt.savefig(os.path.join(pic_dir, '26-3_Transfer_Learning_Concept.png'))
    print("Transfer Learning Concept plot saved.")

plot_transfer_learning_concept()
