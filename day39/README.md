# Day 39: AI 為什麼這樣想？ - XAI (可解釋 AI)

## 1. 前言：黑盒子的恐懼
現在的 AI (尤其是深度學習) 越來越強，但也越來越像一個 **黑盒子 (Black Box)**。
*   **輸入**：一張 X 光片。
*   **輸出**：AI 說「有腫瘤」。
*   **醫生問**：「為什麼？」
*   **AI**：「...... (我不知道，神經網路算出來就是這樣)」

這在醫療、金融、法律等領域是無法接受的。
我們需要 **XAI (Explainable AI)** 來打開這個黑盒子，告訴人類 **「為什麼」**。

## 2. 核心工具：SHAP (夏普值)
SHAP (SHapley Additive exPlanations) 是目前最權威的 XAI 方法，源自於賽局理論。
*   **核心概念**：計算每個特徵對最終預測結果的 **貢獻度**。
*   **比喻**：
    *   **情境**：三個好朋友 (A, B, C) 一起去打工，總共賺了 1000 元。
    *   **問題**：這 1000 元裡面，每個人分別貢獻了多少？
    *   **SHAP**：它會嘗試各種組合 (A 自己做、A+B 做、A+C 做...)，精確算出每個人的「邊際貢獻」。

## 3. 實戰：房價預測的解釋
我們將使用經典的波士頓房價資料集 (Boston Housing)，先訓練一個 XGBoost 模型，然後用 SHAP 來解釋它。

### 3.1 程式碼架構 (`XAI_SHAP.py`)
1.  **訓練模型**：用 XGBoost 預測房價。
2.  **計算 SHAP 值**：使用 `shap.TreeExplainer` 來分析模型。
3.  **畫圖解釋**：
    *   **Summary Plot (總覽圖)**：哪些特徵最重要？(例如：房間數越多越貴？犯罪率越高越便宜？)
    *   **Force Plot (單筆分析)**：針對「某這一間房子」，為什麼 AI 估價這麼高？(因為它離市中心近？還是因為它屋齡低？)

## 4. 執行結果預期
你會看到兩張圖：
1.  **特徵重要性**：`LSTAT` (低收入人口比例) 和 `RM` (房間數) 通常是最關鍵的因素。
2.  **個案分析**：你會看到紅色條 (推高房價) 和藍色條 (拉低房價) 的拉鋸戰，清楚解釋 AI 的決策邏輯。

## 5. 下一關預告
了解了 AI 的內心世界後，最後一天我們要挑戰目前最火紅的技術。
Day 40 我們將介紹 **RAG (檢索增強生成)**。
讓 LLM (ChatGPT) 能夠讀懂你的私有資料，回答你公司內部的問題！
