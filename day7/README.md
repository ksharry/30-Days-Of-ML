# Day 07：決策樹 (Decision Tree) — 畫出一張銀行經理看得懂的圖

在前幾天的課程中，我們學習了 SVM 和邏輯回歸。它們雖然強大，但都有一個共同的缺點：**「黑箱 (Black Box)」**。

當模型拒絕了一筆貸款，銀行經理問：「為什麼拒絕他？」如果你的回答是：「因為 $W_1X_1 + W_2X_2...$ 的結果小於 0.5」，經理一定會崩潰。

今天我們要挑戰的是金融風控領域最核心的題目：**信用違約預測 (Credit Risk Assessment)**。

我們將使用德國信用風險資料集 (German Credit Data)，模擬銀行審核貸款的流程，目標是找出：**什麼樣的人最容易欠錢不還？**

## 0. 歷史小百科：決策樹是誰發明的？

決策樹的誕生是跨領域的結晶：
* **心理學起源 (1966)**：**Earl B. Hunt** 研究人類如何學習概念 (CLS)，奠定了樹狀結構基礎。
* **AI 之父 (1986)**：**Ross Quinlan** 發明了 **ID3** 與 **C4.5**，引入了「資訊熵 (Entropy)」的概念，是電腦科學界的經典。
* **統計大師 (1984)**：**Leo Breiman** 提出了 **CART** (Classification and Regression Trees)，這也是 Python Scikit-learn 目前採用的核心演算法（使用 Gini 不純度）。

## 1. 經典資料集介紹 (German Credit Data)
![German Credit Data](https://github.com/ksharry/30-Days-Of-ML/blob/main/day7/pic/7-1.jpg?raw=true)
這份資料集包含 1,000 筆真實的貸款紀錄，包含以下關鍵欄位，每一個都是徵信審核的重點：

| 特徵欄位 (Feature) | 意義 | 觀察重點 |
| :--- | :--- | :--- |
| **checking_status** | 支票/存款帳戶餘額 | 這是最重要的現金流指標 (e.g., < 0 DM, > 200 DM)。 |
| **duration** | 貸款期限 (月) | 借越久，變數越多，風險通常越高。 |
| **credit_history** | 信用歷史 | 過去是否有準時還款，或是已經有呆帳紀錄。 |
| **purpose** | 貸款用途 | 買車？買房？還是買家電？(不同用途違約率不同)。 |
| **credit_amount** | 貸款金額 | 借多少錢。 |
| **savings_status** | 儲蓄帳戶餘額 | 另一個資產證明指標。 |
| **employment** | 就業年資 | 工作穩不穩定。 |
| **target (Class)** | **信用評等** | **Good (信用好) vs. Bad (違約風險)。** |

---

## 2. 原理與公式：電腦是怎麼「做決定」的？

決策樹的邏輯很像玩「終極密碼」或「20 個問題」。它透過不斷問問題（切一刀），試圖把資料分得越來越「乾淨」。

### 核心術語：
1.  **根節點 (Root Node)**：最上面的起點，代表**最重要**的審核標準。
2.  **節點 (Node)**：每一次的問答（例如：存款餘額 < 0 嗎？）。
3.  **葉節點 (Leaf)**：最終的決策結果（例如：核貸 / 拒貸）。
4.  **Gini Impurity (吉尼不純度)**：衡量切得乾不乾淨的指標。0 代表非常乾淨（裡面全是同一類人）。

### 核心指標：Gini Impurity (吉尼不純度)

電腦怎麼知道要切「存款餘額」還是切「貸款期限」？它會計算切完之後的**純度**。
最常用的指標是 **Gini Impurity**。

$$Gini = 1 - \sum_{i=1}^{C} (p_i)^2$$

* $p_i$：該類別在節點中出現的機率。
* **直觀理解**：

如果一個群體裡 **100% 都是違約者**（非常純）：$Gini = 1 - (1^2) = 0$。**(數值越小越好)**

如果一個群體裡 **50% 違約、50% 還款**（最混亂）：$Gini = 1 - (0.5^2 + 0.5^2) = 0.5$。

### 決策樹的生長步驟 (CART 演算法)：
1.  遍歷所有特徵 (餘額、期限...) 和所有可能的切分點。
2.  算出每一種切法後的 **Gini 係數**。
3.  選擇讓 Gini 下降最多（資訊獲利最大）的那個特徵切下去。
4.  重複上述步驟，直到分乾淨或達到停止條件。

---

## 3. 實戰：信用違約預測 (Credit Risk)

### Python 程式碼實作
*(請使用 `german_credit_data.csv` 與提供的 Python 腳本進行分析)*

執行程式後，我們會得到一張漂亮的樹狀圖，讓我們來解讀這張圖背後的商業意義。

### 圖解分析 (Visualization Analysis)

![Decision Tree](https://github.com/ksharry/30-Days-Of-ML/blob/main/day7/pic/7-2.jpg?raw=true)

**1. 找出第一關鍵因素 (Root Node)**
請看樹的最頂端（根節點），判斷條件是：
> **checking_status <= 1.5** (支票帳戶狀態)

這代表模型認為**「帳戶目前的等級或餘額狀態」**是決定信用的最重要門檻。
* **True (向左走)**：這群人的帳戶狀態數值較低（可能代表餘額較少或為負）。這條路往下走，出現了藍色的「Bad」節點，代表**高風險族群多集中在這一側**。
* **False (向右走)**：這群人的帳戶狀態數值較高（可能代表餘額較高或無須支票帳戶）。這條路整片都是橘色，代表這類客戶**絕大多數信用都是 Good**。

**2. 挖掘次要因素與「地雷區」**
如果我們往風險較高的左邊走（True），下一個關鍵判斷是：
> **duration <= 22.5** (貸款期間)

這裡點出了一個很重要的商業邏輯：
* **短期貸款 (<= 22.5個月)**：即使帳戶狀態普通，如果只借不到兩年，風險還算可控（左下角大多仍是橘色 Good）。
* **長期貸款 (> 22.5個月)**：這條路往右下走遇到了一個**淺藍色的節點 (class = Bad)**。
    * 這意味著：如果你**「帳戶狀態不佳」**且**「借款時間長（超過22.5個月）」**，再搭配**「存款狀態 (savings_status) 低落」**，你極高機率會被歸類為違約客戶（Bad）。

**3. 右側的安全名單**
如果第一關判斷往右走（False，帳戶狀態佳），模型接著看的是：
> **other_payment_plans <= 0.5** (是否有其他分期計畫)

這代表對於財務狀況好的人，模型只須確認他有沒有揹負其他分期付款。但不論有無，右側這群人的最終結果幾乎都是橘色 (Good)，只是深淺程度不同。

**4. 顏色深淺的意義**
* **橘色 (Good)**：代表信用良好的客戶。顏色越深，代表模型對這個判斷越有信心。
* **藍色 (Bad)**：代表違約風險高的客戶。圖中唯一的藍色區塊出現在中間偏左的位置，特徵是**「帳戶差 + 借太久 + 存款少」**。

---

## 4. 特徵重要性 (Feature Importance)

除了畫樹，決策樹還能直接告訴我們每個特徵的「分數」。

執行程式碼中的 `feature_importances_` 部分，你會看到類似這樣的長條圖：
![Feature Importance](https://github.com/ksharry/30-Days-Of-ML/blob/main/day7/pic/7-3.jpg?raw=true)

1.  **Checking Status (帳戶狀態)**：權重通常最高。
2.  **Credit Amount (貸款金額)**：借多少錢當然重要。
3.  **Duration (期限)**：借多久影響變數。
4.  **Age (年齡)**：雖然有影響，但通常不如上述財務指標重要。

**[數據洞察]**：這張圖告訴我們，對於信用評分來說，**「現在有多少錢 (Checking Status)」比「你是誰 (Age/Job)」更重要**。這就是數據驅動決策的價值。

---

## 5. 模型評估：這張考卷考得怎麼樣？

訓練完模型後，我們不能只看它「背答案」的能力，重點是它面對沒看過的客戶（測試集）表現如何。

### 整體成績單 (Performance Metrics)

首先，我們來看模型的三項核心指標。這些數字告訴我們，模型並沒有「死記硬背」（過擬合），因為訓練分數與測試分數相當接近。

* 🔹 **訓練集準確率 (Training Acc): 0.75** (平常練習考 75 分)
* 🔹 **交叉驗證準確率 (Validation Acc): 0.72 (+/- 0.04)** (多次模擬考平均 72 分)
* 🔹 **測試集準確率 (Test Acc): 0.74** (期末考 74 分，表現穩定)

### 圖表解讀 (Visualization Analysis)

我們進一步透過 **混淆矩陣 (Confusion Matrix)** 與 **ROC 曲線** 來拆解這 74 分是怎麼來的。

![Confusion Matrix and ROC Curve](https://github.com/ksharry/30-Days-Of-ML/blob/main/day7/pic/7-4.jpg?raw=true)

#### **1. 左圖：混淆矩陣 (Confusion Matrix)**
這張圖告訴我們模型「猜對了多少」以及「錯在哪裡」。對於銀行來說，**犯錯的種類**比總分更重要。

* **✅ 猜對了 (對角線)：**
    * **185 (True Good)**：模型預測信用好，實際上也真的好。 (銀行賺到利息)
    * **36 (True Bad)**：模型預測會違約，實際上也真的違約。 (銀行成功避雷，守住本金)

* **❌ 猜錯了 (非對角線) —— 這是我們要注意的！**
    * **24 (False Bad / 誤殺)**：客戶其實信用很好，但模型誤以為他會違約而拒貸。(銀行少賺利息，但風險不大)
    * **55 (False Good / 漏抓)**：**這是最危險的數字！** 客戶其實會違約，但模型誤以為他信用好而放款。(銀行面臨呆帳損失)

**[商業洞察]**：目前模型漏抓了 55 個壞客戶，這比誤殺 24 個好客戶嚴重得多。在未來的優化中（例如 Day 08 的隨機森林），我們的目標是要降低這個左下角的數字。

#### **2. 右圖：ROC 曲線 (ROC Curve)**
這條橘色曲線代表模型的「鑑別能力」。

* **虛線 (對角線)**：代表隨機亂猜 (AUC = 0.5)。
* **橘色實線**：我們的模型表現。
* **AUC = 0.73**：曲線下面積 (Area Under Curve)。
    * 這代表如果你隨機抓一個好人和一個壞人，模型有 **73%** 的機率能正確分辨誰是誰。
    * 一般來說，0.7~0.8 算是「尚可 (Fair)」的接受範圍。雖然不是神準，但已經比瞎猜好上許多，具備初步的商用價值。

---

## 6. 戰略總結：模型訓練的火箭發射之旅

決策樹雖然好解釋，但它有一個天生的致命傷：**「容易鑽牛角尖」**。如果不加限制，它會試圖把訓練資料分得一清二楚，導致模型變得過度複雜。

我們可以用下面這張**「火箭發射圖」**來理解模型訓練的過程與挑戰：

![模型訓練與參數調整的火箭發射之旅](https://github.com/ksharry/30-Days-Of-ML/blob/main/day2/pic/2-6.jpg?raw=true)

訓練一個 AI 模型，就像是要發射一枚火箭進入軌道，過程中有兩個主要的失敗情境：

### 情境一：欠擬合 (Underfitting) — 推力不足，無法升空
* **圖中位置**：左側路徑。
* **現象**：火箭剛點火就掉下來了。這代表模型**「太簡單」**，連訓練集 (考古題) 都做不好。
* **在決策樹中**：像是你限制樹只能長 1 層 (Depth=1)，不管誰來借錢都拒絕。
* **解決方案**：**增加複雜度**。讓樹長深一點，增加特徵欄位。

### 情境二：過擬合 (Overfitting) — 動力太強，失去控制
* **圖中位置**：右側路徑（**這是決策樹最常遇到的問題**）。
* **現象**：火箭飛得很快，但方向亂竄，最後炸毀。這代表模型在訓練集表現滿分 (100 分)，但在測試集 (沒看過的新客戶) 表現極差。
* **在決策樹中**：樹長得太深太茂密，把雜訊（Noise）也當成規則背下來了。就像行員死背了過去 1000 個客戶的長相，結果來了一個新客戶長得稍微不一樣，他就不知道該不該借了。
* **解決方案**：**限制複雜度 (Regularization)**。
    * **剪枝 (Pruning)**：限制樹的最大深度 (例如設定 `max_depth=3`)，就像幫火箭裝上穩定翼。
    * **增加數據**：提供更多燃料，讓模型看過更多樣貌。

### 最終目標：表現良好 (Good Fit) — 成功入軌
* 當我們透過調整參數（如 `max_depth`, `min_samples_split`），在「太簡單」與「太複雜」之間找到平衡點，模型就能在測試資料上穩定運行，這才是我們追求的完美 AI。

---
## 7. 總結與比較 (Conclusion)

讓我們看看目前的最終排行榜：

| 模型 | Day | 特性 | 鐵達尼號準確率 |
| :--- | :---: | :--- | :---: |
| **邏輯回歸** | 04 | 畫直線，只求分開 | 81.00% |
| **KNN (K=17)** | 05 | 看鄰居，非線性直覺 | 81.56% |
| **SVM (Tuned)** | 06 | 高維魔法 + 參數優化 | 82.12% |
| **決策樹 (DT)** | **07** | **白箱模型，可畫圖解釋** | **74.00%** |



##  決策樹的致命傷：過擬合 (Overfitting)

決策樹雖然好解釋，但它有一個巨大的缺點：**「鑽牛角尖」**。

如果你不限制樹的生長深度 (`max_depth`)，它會為了把每一個訓練樣本都分對，而長出非常複雜、非常深的樹。這就像一個銀行行員死背了過去 1000 個客戶的長相，結果來了一個新客戶長得稍微不一樣，他就不知道該不該借了。

### 怎麼辦？
* **剪枝 (Pruning)**：限制樹只能長到 3 層或 5 層。
* **集成學習 (Ensemble)**：這就是我們明天的主題。既然一棵樹容易鑽牛角尖，那我們種 **100 棵樹** 來投票，不就穩定了嗎？

**Next Day 預告：**
明天我們將進入 **Day 08：隨機森林 (Random Forest)**，學習如何結合一百個 AI 的智慧，打造出高準確度且穩健的模型！