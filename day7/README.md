# Day 07：決策樹 (Decision Tree) — 畫出一張銀行經理看得懂的圖

在前幾天的課程中，我們學習了 SVM 和邏輯回歸。它們雖然強大，但都有一個共同的缺點：**「黑箱 (Black Box)」**。

當模型拒絕了一筆貸款，銀行經理問：「為什麼拒絕他？」如果你的回答是：「因為 $W_1X_1 + W_2X_2...$ 的結果小於 0.5」，經理一定會崩潰。

今天我們要挑戰的是金融風控領域最核心的題目：**信用違約預測 (Credit Risk Assessment)**。

我們將使用德國信用風險資料集 (German Credit Data)，模擬銀行審核貸款的流程，目標是找出：**什麼樣的人最容易欠錢不還？**

## 0. 歷史小百科：決策樹是誰發明的？

決策樹的誕生是跨領域的結晶：
* **心理學起源 (1966)**：**Earl B. Hunt** 研究人類如何學習概念 (CLS)，奠定了樹狀結構基礎。
* **AI 之父 (1986)**：**Ross Quinlan** 發明了 **ID3** 與 **C4.5**，引入了「資訊熵 (Entropy)」的概念，是電腦科學界的經典。
* **統計大師 (1984)**：**Leo Breiman** 提出了 **CART** (Classification and Regression Trees)，這也是 Python Scikit-learn 目前採用的核心演算法（使用 Gini 不純度）。

## 1. 經典資料集介紹 (German Credit Data)
![German Credit Data](https://github.com/ksharry/30-Days-Of-ML/blob/main/day7/pic/7-1.jpg?raw=true)
這份資料集包含 1,000 筆真實的貸款紀錄，包含以下關鍵欄位，每一個都是徵信審核的重點：

| 特徵欄位 (Feature) | 意義 | 觀察重點 |
| :--- | :--- | :--- |
| **checking_status** | 支票/存款帳戶餘額 | 這是最重要的現金流指標 (e.g., < 0 DM, > 200 DM)。 |
| **duration** | 貸款期限 (月) | 借越久，變數越多，風險通常越高。 |
| **credit_history** | 信用歷史 | 過去是否有準時還款，或是已經有呆帳紀錄。 |
| **purpose** | 貸款用途 | 買車？買房？還是買家電？(不同用途違約率不同)。 |
| **credit_amount** | 貸款金額 | 借多少錢。 |
| **savings_status** | 儲蓄帳戶餘額 | 另一個資產證明指標。 |
| **employment** | 就業年資 | 工作穩不穩定。 |
| **target (Class)** | **信用評等** | **Good (信用好) vs. Bad (違約風險)。** |

---

## 2. 原理與公式：電腦是怎麼「做決定」的？

決策樹的邏輯很像玩「終極密碼」或「20 個問題」。它透過不斷問問題（切一刀），試圖把資料分得越來越「乾淨」。

### 核心術語：
1.  **根節點 (Root Node)**：最上面的起點，代表**最重要**的審核標準。
2.  **節點 (Node)**：每一次的問答（例如：存款餘額 < 0 嗎？）。
3.  **葉節點 (Leaf)**：最終的決策結果（例如：核貸 / 拒貸）。
4.  **Gini Impurity (基尼不純度)**：衡量切得乾不乾淨的指標。0 代表非常乾淨（裡面全是同一類人）。

### 核心指標：Gini Impurity (基尼不純度)

電腦怎麼知道要切「存款餘額」還是切「貸款期限」？它會計算切完之後的**純度**。
最常用的指標是 **Gini Impurity**。

$$Gini = 1 - \sum_{i=1}^{C} (p_i)^2$$

* $p_i$：該類別在節點中出現的機率。
* **直觀理解**：
    * 如果一個群體裡 **100% 都是違約者**（非常純）：$Gini = 1 - (1^2) = 0$。**(數值越小越好)**
    * 如果一個群體裡 **50% 違約、50% 還款**（最混亂）：$Gini = 1 - (0.5^2 + 0.5^2) = 0.5$。

### 決策樹的生長步驟 (CART 演算法)：
1.  遍歷所有特徵 (餘額、期限...) 和所有可能的切分點。
2.  算出每一種切法後的 **Gini 係數**。
3.  選擇讓 Gini 下降最多（資訊獲利最大）的那個特徵切下去。
4.  重複上述步驟，直到分乾淨或達到停止條件。

---

## 3. 實戰：信用違約預測 (Credit Risk)

### Python 程式碼實作
*(請使用 `german_credit_data.csv` 與提供的 Python 腳本進行分析)*

執行程式後，我們會得到一張漂亮的樹狀圖，讓我們來解讀這張圖背後的商業意義。

### 圖解分析 (Visualization Analysis)

![Decision Tree](https://github.com/ksharry/30-Days-Of-ML/blob/main/day7/pic/7-2.jpg?raw=true)

**1. 找出第一關鍵因素 (Root Node)**
請看樹的最頂端（根節點），上面的文字通常會是：
> **checking_status_no checking <= 0.5** (或是類似的餘額判斷)

這代表模型學習後發現：**「手上有沒有現金（流動資產）」是決定是否違約的最重要單一因素。**
* **True (向左走)**：帳戶狀況正常的人，大部分信用是 **Good**。
* **False (向右走)**：沒有支票帳戶或餘額為負的人，違約風險大幅上升。

**2. 挖掘次要因素**
如果我們往風險較高那條路走，下一個節點可能會問：
> **duration <= 47.5** (貸款期限)

這告訴我們，如果你的帳戶沒錢，**又想借很長期的款項**（例如超過 4 年），那麼違約機率極高。這符合銀行「救急不救窮」的風控邏輯。

**3. 顏色深淺的意義**
* **深色**：代表信心度很高（例如深藍色代表這個格子裡 95% 都是優質客戶）。
* **淺色**：代表混雜度很高（這個群體裡好壞客戶各半，模型還不太確定）。

---

## 4. 特徵重要性 (Feature Importance)

除了畫樹，決策樹還能直接告訴我們每個特徵的「分數」。

執行程式碼中的 `feature_importances_` 部分，你會看到類似這樣的長條圖：
![Feature Importance](https://github.com/ksharry/30-Days-Of-ML/blob/main/day7/pic/7-3.jpg?raw=true)

1.  **Checking Status (帳戶狀態)**：權重通常最高。
2.  **Credit Amount (貸款金額)**：借多少錢當然重要。
3.  **Duration (期限)**：借多久影響變數。
4.  **Age (年齡)**：雖然有影響，但通常不如上述財務指標重要。

**[數據洞察]**：這張圖告訴我們，對於信用評分來說，**「現在有多少錢 (Checking Status)」比「你是誰 (Age/Job)」更重要**。這就是數據驅動決策的價值。

---

## 5. 決策樹的致命傷：過擬合 (Overfitting)

決策樹雖然好解釋，但它有一個巨大的缺點：**「鑽牛角尖」**。

如果你不限制樹的生長深度 (`max_depth`)，它會為了把每一個訓練樣本都分對，而長出非常複雜、非常深的樹。這就像一個銀行行員死背了過去 1000 個客戶的長相，結果來了一個新客戶長得稍微不一樣，他就不知道該不該借了。

### 怎麼辦？
* **剪枝 (Pruning)**：限制樹只能長到 3 層或 5 層。
* **集成學習 (Ensemble)**：這就是我們明天的主題。既然一棵樹容易鑽牛角尖，那我們種 **100 棵樹** 來投票，不就穩定了嗎？

**Next Day 預告：**
明天我們將進入 **Day 08：隨機森林 (Random Forest)**，學習如何結合一百個 AI 的智慧，打造出高準確度且穩健的模型！