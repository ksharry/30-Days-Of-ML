import sys
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score

# è¨­å®šä¸­æ–‡å­—å‹ (ä»¥å…äº‚ç¢¼)
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei'] 
plt.rcParams['axes.unicode_minus'] = False

def main():
    print("ğŸš€ ç¨‹å¼é–‹å§‹åŸ·è¡Œ...")

    # --- 1. è¼‰å…¥è³‡æ–™ ---
    filename = 'german_credit_data.csv'
    df = None

    if os.path.exists(filename):
        print(f"ğŸ“‚ ç™¼ç¾æœ¬åœ°æª”æ¡ˆï¼š{filename}ï¼Œæ­£åœ¨è®€å–...")
        try:
            # å˜—è©¦è®€å–ï¼Œè™•ç†å¯èƒ½çš„æ ¼å¼å•é¡Œ
            df = pd.read_csv(filename)
            # å¦‚æœè®€é€²ä¾†åªæœ‰ä¸€æ¬„ï¼Œå¯èƒ½æ˜¯åˆ†éš”ç¬¦è™Ÿå•é¡Œ (ä¾‹å¦‚æ˜¯ Tab åˆ†éš”)
            if df.shape[1] < 2:
                df = pd.read_csv(filename, sep='\t')
        except Exception as e:
            print(f"âš ï¸ è®€å– CSV å¤±æ•—ï¼Œå˜—è©¦ä½¿ç”¨ Tab åˆ†éš”: {e}")
            try:
                df = pd.read_csv(filename, sep='\t')
            except:
                pass
    
    if df is None:
        print("ğŸŒ æœ¬åœ°ç„¡æª”æ¡ˆï¼Œæ­£åœ¨å˜—è©¦å¾ OpenML ä¸‹è¼‰è³‡æ–™...")
        try:
            credit_data = fetch_openml(name='credit-g', version=1, as_frame=True)
            df = credit_data.frame
            df.to_csv(filename, index=False)
            print("âœ… ä¸‹è¼‰æˆåŠŸï¼")
        except Exception as e:
            print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
            return

    print(f"ğŸ“Š è³‡æ–™é›†è¼‰å…¥å®Œæˆã€‚å¤§å°: {df.shape}")

    # --- 2. è³‡æ–™å‰è™•ç† (å…±ç”¨éƒ¨åˆ†) ---
    print("âš™ï¸ æ­£åœ¨é€²è¡Œè³‡æ–™å‰è™•ç†...")

    # è™•ç†ç›®æ¨™æ¬„ä½
    if 'class' in df.columns:
        target_col = 'class'
    elif 'target' in df.columns:
        target_col = 'target'
    else:
        target_col = df.columns[-1]

    # çµ±ä¸€ Target ç‚º 0/1 (1 = Bad/Risk, 0 = Good)
    if df[target_col].dtype == 'object':
        unique_vals = df[target_col].unique()
        if 'bad' in unique_vals:
             df['target'] = df[target_col].map({'bad': 1, 'good': 0})
        else:
             le_target = LabelEncoder()
             df['target'] = le_target.fit_transform(df[target_col])
    else:
        # å‡è¨­å·²ç¶“æ˜¯æ•¸å€¼ï¼Œä¸” 1/2 æˆ– 0/1
        # è‹¥æ˜¯ 1/2 (1=good, 2=bad)ï¼Œéœ€è½‰æ›
        unique_vals = df[target_col].unique()
        if 2 in unique_vals and 1 in unique_vals:
             df['target'] = df[target_col].map({2: 1, 1: 0})
        else:
             df['target'] = df[target_col]

    # ç§»é™¤åŸå§‹ class æ¬„ä½ (é¿å… Data Leakage)
    if target_col != 'target':
        df = df.drop(columns=[target_col])

    # ä¿®æ­£: å°‡ category é¡å‹è½‰ç‚º objectï¼Œé¿å… fillna å ±éŒ¯
    for col in df.select_dtypes(include=['category']).columns:
        df[col] = df[col].astype('object')

    # å¡«è£œç¼ºå¤±å€¼
    df = df.fillna(0)

    # ==========================================
    # åˆ†æ”¯ A: Decision Tree (ä½¿ç”¨ Label Encoding)
    # é©åˆç•«å‡ºæ˜“è®€çš„æ±ºç­–æ¨¹
    # ==========================================
    print("\nğŸŒ² [A] æº–å‚™ Decision Tree è³‡æ–™ (Label Encoding)...")
    df_dt = df.copy()
    encoders = {}
    for col in df_dt.columns:
        if col == 'target': continue
        if df_dt[col].dtype == 'object' or df_dt[col].dtype.name == 'category':
            le = LabelEncoder()
            df_dt[col] = le.fit_transform(df_dt[col].astype(str))
            encoders[col] = le

    X_dt = df_dt.drop('target', axis=1)
    y_dt = df_dt['target']
    X_train_dt, X_test_dt, y_train_dt, y_test_dt = train_test_split(X_dt, y_dt, test_size=0.3, random_state=42)

    print("ğŸ§  è¨“ç·´ Decision Tree (Max Depth = 3)...")
    dt_model = DecisionTreeClassifier(max_depth=3, random_state=42)
    dt_model.fit(X_train_dt, y_train_dt)
    
    y_pred_dt = dt_model.predict(X_test_dt)
    print(f"ğŸ“Š Decision Tree æº–ç¢ºç‡: {accuracy_score(y_test_dt, y_pred_dt):.2f}")

    # ==========================================
    # åˆ†æ”¯ B: Decision Tree (ä½¿ç”¨ One-Hot Encoding)
    # é©åˆè¿½æ±‚é«˜æº–ç¢ºç‡èˆ‡ç‰¹å¾µé‡è¦æ€§åˆ†æ
    # ==========================================
    print("\nğŸŒ³ [B] æº–å‚™ Decision Tree è³‡æ–™ (One-Hot Encoding)...")
    df_rf = df.copy()
    cat_cols = df_rf.select_dtypes(include=['object', 'category']).columns.tolist()
    if 'target' in cat_cols: cat_cols.remove('target')
    
    df_rf = pd.get_dummies(df_rf, columns=cat_cols, drop_first=True)
    
    X_rf = df_rf.drop('target', axis=1)
    y_rf = df_rf['target']
    X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.3, random_state=42, stratify=y_rf)
    
    # æ¨™æº–åŒ–
    scaler = StandardScaler()
    X_train_rf = pd.DataFrame(scaler.fit_transform(X_train_rf), columns=X_train_rf.columns)
    X_test_rf = pd.DataFrame(scaler.transform(X_test_rf), columns=X_test_rf.columns)

    print("ğŸ§  è¨“ç·´ Decision Tree (n_estimators=100)...")
    dt_model = DecisionTreeClassifier(n_estimators=100, max_depth=10, random_state=42, class_weight='balanced')
    dt_model.fit(X_train_rf, y_train_rf)
    
    y_pred_rf = dt_model.predict(X_test_rf)
    print(f"ğŸ“Š Decision Tree æº–ç¢ºç‡: {accuracy_score(y_test_rf, y_pred_rf):.2f}")
    print(f"â­ Decision Tree AUC: {roc_auc_score(y_test_rf, dt_model.predict_proba(X_test_rf)[:, 1]):.4f}")

    # ==========================================
    # è¦–è¦ºåŒ–
    # ==========================================
    print("\nğŸ¨ ç¹ªè£½åœ–è¡¨...")
    
    # 1. ç¹ªè£½ Decision Tree
    plt.figure(figsize=(20, 10))
    class_names_list = ['Good', 'Bad'] # 0=Good, 1=Bad
    plot_tree(dt_model, 
              feature_names=X_dt.columns, 
              class_names=class_names_list,
              filled=True, rounded=True, fontsize=10)
    plt.title("Credit Risk Decision Tree (Label Encoded, Depth=3)")
    plt.show()

    # 2. ç¹ªè£½ Decision Tree Feature Importance (æ”¹ç”¨æ±ºç­–æ¨¹çš„ç‰¹å¾µé‡è¦æ€§)
    importances = dt_model.feature_importances_
    indices = np.argsort(importances)[::-1]
    top_n = 10
    
    plt.figure(figsize=(10, 6))
    plt.title("Decision Tree Feature Importance (Top 10)")
    plt.bar(range(top_n), importances[indices[:top_n]], align="center", color='skyblue')
    plt.xticks(range(top_n), X_dt.columns[indices[:top_n]], rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

    print("âœ… æ‰€æœ‰ç¨‹å¼åŸ·è¡Œå®Œç•¢")

if __name__ == "__main__":
    main()