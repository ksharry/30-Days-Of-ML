# Day 04：邏輯回歸 (Logistic Regression) —— 生死一線間

## 0. 歷史小故事：人口增長的極限
我們先回到 19 世紀。

當時，馬爾薩斯的人口論認為「人口會呈現幾何級數爆炸增長」。但比利時數學家 **皮埃爾·弗朗索瓦·費爾許爾斯特 (Pierre François Verhulst)** 覺得這不合理，因為資源是有限的，人口不可能無限膨脹，增長速度到最後一定會慢下來並趨於平緩。

於是他提出了一個呈現 **S 型 (Sigmoid)** 的曲線公式 —— **Logistic Function**。

一百多年後，英國統計學家 **大衛·考克斯 (David Cox)** 將這個概念發揚光大，正式提出了 **邏輯回歸 (Logistic Regression)** 模型。他發現這個「S 型曲線」非常完美地解決了機率問題：它能將任何數值強行壓縮在 0% 到 100% 之間，成為了現代分類演算法的基石。

在 Day 02 與 Day 03，我們處理的是房價預測（回歸問題）。但現實生活中，更多時候我們要面對的是 **「是非題」**：
* 這封信是垃圾郵件嗎？(Yes/No)
* 這位病人有癌症嗎？(Positive/Negative)
* **這位乘客能在鐵達尼號倖存嗎？(Survived/Died)**

今天，我們開啟新的故事線 —— **鐵達尼號生存預測**。我們將使用最經典的分類演算法：**邏輯回歸 (Logistic Regression)**。

---

## 1 資料介紹
### 1.1 資料集介紹 (Data Dictionary)

本實作使用 kaggle 競賽預測生存率的 [Titanic](https://www.kaggle.com/competitions/titanic/data) 資料集。

![Titanic](https://github.com/ksharry/30-Days-Of-ML/blob/main/day4/pic/4-1.jpg?raw=true)

| 欄位名稱 (Column) | 說明 (Description) | 備註 (Key) |
| :--- | :--- | :--- |
| **Survived** | 生存與否 | 0 = 死亡, 1 = 生存 |
| **Pclass** | 艙等 (社經地位) | 1 = 頭等艙, 2 = 二等艙, 3 = 三等艙 |
| **Sex** | 性別 | male / female |
| **Age** | 年齡 | 部分資料有缺失 |
| **SibSp** | 同船兄弟姊妹/配偶數 | # of siblings / spouses aboard |
| **Parch** | 同船父母/子女數 | # of parents / children aboard |
| **Ticket** | 船票號碼 | |
| **Fare** | 票價 | |
| **Cabin** | 客艙號碼 | 缺失值較多 |
| **Embarked** | 登船港口 | C = Cherbourg, Q = Queenstown, S = Southampton |

### 1.2 數據預處理 (Data Preprocessing)

我們使用 Python 的 `sklearn` 來實作。為了讓電腦讀懂資料，我們做了兩件重要的預處理：

1.  **填補缺失值 (Missing Values)：** 很多乘客的年齡是空的，我們用「中位數」填補，避免誤導模型。
2.  **獨熱編碼 (One-Hot Encoding)：** 電腦看不懂 "Male" 和 "Female"。我們將其轉換為數字。
邏輯回歸的運作可以拆解成兩個步驟。你剛才看到的那些數學符號，其實每一個都對應到鐵達尼號的具體情境。

## 2 解構神秘公式
### 2.1 第一步：線性計分 (The Linear Score)
模型會先幫每位乘客算一個「生存分數」($z$)，公式如下：

$$z = w_1 x_1 + w_2 x_2 + \dots + b$$

**變數對照表 (Variable Explanation)：**
* **$z$ (Score)**：這是模型算出來的**線性分數**。分數越高，代表存活機率越大；分數越低（負數），代表越可能死亡。
* **$x$ (Features)**：這是乘客的**特徵資料**。
    * $x_1$：可能是「性別 (Sex)」
    * $x_2$：可能是「年齡 (Age)」
    * $x_3$：可能是「艙等 (Pclass)」
* **$w$ (Weights)**：這是**權重**，也就是模型學到的「經驗」。
    * 如果 $w_1$ (性別權重) 是很大的**負數**，代表如果是男性，分數 $z$ 會被扣很多分。
    * 如果 $w_3$ (艙等權重) 是正數，代表艙等越高，分數加越多。
* **$b$ (Bias)**：**偏差值**。代表基礎分數，就像是考試的基本分。

### 2.2 第二步：機率轉換 (Sigmoid Function)
算出來的 $z$ 可能是 100 或是 -500，這不像是「機率」。我們需要把它壓縮到 **0 ~ 1** 之間，這就是著名的 **Sigmoid 函數**：

$$\sigma(z) = \frac{1}{1 + e^{-z}}$$

**變數對照表：**
* **$\sigma(z)$**：讀作 Sigma，這裡代表最終預測的 **生存機率 (Probability)**。範圍在 0% 到 100%。
* **$e$**：自然對數的底數 (約等於 2.718)。
* **$z$**：就是第一步算出來的那個「生存分數」。

**直觀理解：**
* 當分數 $z$ 很大時 (例如 10)，$e^{-10} 接近 0，結果接近 $\frac{1}{1} = 1$ (100% 存活)。
* 當分數 $z$ 很負時 (例如 -10)，$e^{10} 很大，分母變超大，結果接近 $0$ (0% 存活)。

---

## 3. 實驗結果：鐵達尼號數據 (The Titanic Experiment)

### 3.1 混淆矩陣 (Confusion Matrix)
![Confusion Matrix](https://github.com/ksharry/30-Days-Of-ML/blob/main/day4/pic/4-2.jpg?raw=true)

模型跑完後，準確率大約落在 **81%**。
* **TP (True Positive):** 模型猜他活，他也真的活了。
* **FN (False Negative):** 模型猜他會死，結果他奇蹟生還（遺憾的錯誤）。

---

## 4. 深度分析：誰最容易活下來？

透過觀察程式跑出來的 **係數圖 (Coefficients)**，我們發現了 $w$ (權重) 的秘密：

1.  **`Sex_male` (權重約 -2.5)**：這是負值最大的特徵。代表只要 $x$ (性別) 是男性，生存分數 $z$ 就會被重扣 2.5 分。這反映了「婦孺優先」。
2.  **`Pclass` (權重約 -0.9)**：也是負值。代表艙等數字越大 (3等艙)，生存機率越低。

---

## 5. 總結 (Conclusion)

邏輯回歸其實就是在做兩件事：
1.  算出一個分數 $z$（根據性別、年齡加權）。
2.  用 Sigmoid 函數把分數變成機率。

**Next Step:**
邏輯回歸畫出的這條「生死界線」是一條**直線**。但如果有更複雜的關係（例如：只有「小孩」和「老人」易存活，中間的壯年人易死亡），直線切不開怎麼辦？
**Day 05 - K-近鄰演算法 (KNN)** 將登場，我們將用「物以類聚」的方式來重新挑戰鐵達尼號！