# Day 08：隨機森林 (Random Forest) — 三個臭皮匠，勝過諸葛亮

昨天 Day 07 我們介紹了 **決策樹 (Decision Tree)**，它就像一位銀行經理，能畫出清楚的規則告訴我們為什麼拒貸。但我們也發現了它的致命傷：**「鑽牛角尖 (Overfitting)」**。它太容易死記硬背，導致換了新客戶就不準了。

今天我們要介紹機器學習競賽 (Kaggle) 中的長青樹、表格資料的王者：**隨機森林 (Random Forest)**。

如果不相信一個專家的判斷，那就找一百個專家來投票吧！

## 0. 歷史小百科：公牛的重量與群眾的智慧

隨機森林的核心概念——**「集成學習 (Ensemble Learning)」**，其靈感可以追溯到 1906 年的一場鄉村實驗。

英國統計學家 **法蘭西斯·高爾頓 (Francis Galton)** 參觀了普利茅斯的一個家畜展。現場舉辦了一個猜謎遊戲：讓大家猜一隻被宰殺後的公牛有多重。

現場有 **800 位參賽者**，其中有屠夫（專家），也有一般的農夫和路人（非專家）。
* **個別結果**：沒有任何一個人（包括最厲害的屠夫）猜中準確的重量 **1198 磅**。
* **集體結果**：當高爾頓把這 800 個人的猜測數字全部加起來取 **平均值** 時，神奇的事情發生了——平均數是 **1197 磅**！只差了 1 磅。

這證明了 **「群眾的智慧 (The Wisdom of Crowds)」**：許多個「略有偏差」的判斷集合起來，往往比單一專家的判斷更準確。這就是隨機森林的靈魂。

## 1. 原理：怎麼打造一座森林？

隨機森林 (Random Forest) 簡單來說，就是 **「種植 100 棵決策樹，然後讓它們投票」**。

但如果這 100 棵樹都長得一模一樣，那投出來的票也是一樣的，沒有意義。為了讓樹「不一樣」，隨機森林引入了兩個隨機機制（Bagging）：

### A. 資料隨機 (Bootstrap Sample)
假設銀行有 1000 筆客戶資料。
* **第 1 棵樹**：隨機抽 800 筆資料來學（可能重複抽到某些人）。
* **第 2 棵樹**：另外隨機抽 800 筆資料來學。
* **結果**：每棵樹看到的「世界」都略有不同，避免大家一起學壞。

### B. 特徵隨機 (Feature Randomness)
這是最關鍵的一步。在做決策（切分節點）時，決策樹通常會看所有特徵（存款、年齡、性別...）。但隨機森林強迫每一棵樹 **「只能隨機挑幾個特徵來看」**。

* 這就像 **「瞎子摸象」**：
    * **樹 A** 摸到了象鼻（只看到存款）。
    * **樹 B** 摸到了象腿（只看到年齡）。
    * **樹 C** 摸到了象耳（只看到性別）。
* 雖然單看一棵樹都不全面，但把 100 棵樹拼起來，就能還原整隻大象，而且不會被單一特徵誤導。

## 1. 經典資料集介紹 (German Credit Data)
![German Credit Data](https://github.com/ksharry/30-Days-Of-ML/blob/main/day7/pic/7-1.jpg?raw=true)
這份資料集包含 1,000 筆真實的貸款紀錄，包含以下關鍵欄位，每一個都是徵信審核的重點：

| 特徵欄位 (Feature) | 意義 | 觀察重點 |
| :--- | :--- | :--- |
| **checking_status** | 支票/存款帳戶餘額 | 這是最重要的現金流指標 (e.g., < 0 DM, > 200 DM)。 |
| **duration** | 貸款期限 (月) | 借越久，變數越多，風險通常越高。 |
| **credit_history** | 信用歷史 | 過去是否有準時還款，或是已經有呆帳紀錄。 |
| **purpose** | 貸款用途 | 買車？買房？還是買家電？(不同用途違約率不同)。 |
| **credit_amount** | 貸款金額 | 借多少錢。 |
| **savings_status** | 儲蓄帳戶餘額 | 另一個資產證明指標。 |
| **employment** | 就業年資 | 工作穩不穩定。 |
| **target (Class)** | **信用評等** | **Good (信用好) vs. Bad (違約風險)。** |

---

## 2. 圖解分析：森林告訴了我們什麼？

由於我們有 100 棵樹，畫出結構圖會變成一團亂麻。取而代之的是，隨機森林給了我們一張更有商業價值的圖表：**特徵重要性 (Feature Importance)**。

![Feature Importance Chart](https://github.com/ksharry/30-Days-Of-ML/blob/main/day8/pic/8-1.jpg?raw=true)

### A. 左圖：混淆矩陣 (Confusion Matrix) — 模型的成績單

這張圖顯示了模型在測試集（共 300 筆客戶資料）上的表現。總體準確率約為 **76%** $((196+32)/300)$，這在信用風控領域是一個相當不錯的基準。

我們來拆解這四個數字背後的商業意義：

* **✅ 196 (True Good) - 成功獲利**：
    這是最開心的一群。模型預測他們會還錢，實際上他們也真的還錢了。銀行成功賺取了這 196 位客戶的利息。
* **⚠️ 32 (True Bad) - 成功避險**：
    這是風控的核心價值。模型準確抓出了 32 位會違約的客戶並拒絕了他們，幫銀行守住了本金。
* **❌ 13 (False Bad) - 誤殺好人**：
    模型誤以為這 13 個人很危險，但其實他們信用良好。雖然有點可惜（少賺利息），但對銀行來說，這是可以接受的「保守誤差」。
* **💣 59 (False Good) - 潛在呆帳 (危險區)**：
    **這是我們最需要關注的數字！** 有 59 位客戶其實會違約，但模型卻誤判他們是好人而放款。這顯示隨機森林雖然強大，但在處理「偽裝成好人的壞人」時仍有改進空間（這通常需要透過調整閾值 threshold 或增加更多特徵來解決）。

### B. 右圖：特徵重要性 (Feature Importance) — 誰才是關鍵？

這張長條圖是隨機森林最有價值的部分。它告訴我們：**「在 100 棵樹的投票中，哪些特徵最常被用來區分好壞？」**

請注意這裡的排名變化（與 Day 07 的單一決策樹相比）：

1.  **Credit Amount (貸款金額) 🥇**：
    榮登第一名！這非常有趣。在單一決策樹中，這往往排在後面。但在隨機森林中，模型發現**「借多少錢」**其實是決定違約與否的最強訊號。借得越多，風險波動越大。
2.  **Age (年齡) 🥈**：
    這也是大黑馬！在單一決策樹中，年齡常被忽略。但隨機森林透過隨機特徵採樣，挖掘出了**「年齡與穩定度」**的高度相關性。年長者通常財務更穩定，違約率較低。
3.  **Checking Status (支票帳戶狀態) 🥉**：
    雖然退居第三，但依然是核心指標。現金流（Cash Flow）永遠是王道。
4.  **Duration (貸款期限)**：
    借越久，變數越多，風險越高。這與我們的直覺完全相符。

## 3. 進階實戰：參數調優 (Hyperparameter Tuning)

我們原本的隨機森林模型使用的是「預設值 (Default)」，這就像開法拉利卻只用一檔在跑。為了榨出模型的極限效能，我們使用了 **網格搜索 (GridSearchCV)** 進行了暴力測試，從多種組合中找到了最強的參數配置。

### 最佳參數組合解析

經過電腦運算，我們發現針對德國信用資料集，最強的設定是：

```python
best_params = {
    'class_weight': 'balanced',   # 是否加重壞人權重
    'max_depth': 10,              # 樹的深度限制
    'min_samples_split': 5,       # 節點再切分的最少樣本數
    'n_estimators': 100           # 樹的數量
}
```

## 4. 戰略地圖分析：隨機森林在火箭圖中的位置

讓我們回頭看這張**「模型訓練火箭圖」**，分析從 Day 07 (決策樹) 到 Day 08 (隨機森林) 的戰略轉折。

![Rocket Strategy](https://github.com/ksharry/30-Days-Of-ML/blob/main/day2/pic/2-6.jpg?raw=true)

### 1. Day 07 決策樹的危機：右側的「失控」
在昨天的決策樹中，我們面臨的主要風險是火箭圖右側的路徑：**「過擬合 (Overfitting)」**。

* **現象**：動力太強，失去控制。
* **原因**：單一決策樹為了追求訓練集 100% 正確，長出了太深、太複雜的樹葉，導致它把雜訊也當成規則「死記硬背」了下來。
* **後果**：雖然訓練時看起來很強（飛得很快，分數很高），但一遇到新資料（測試集）就會因為不適應而炸毀。

### 2. Day 08 隨機森林的修正：安裝「穩定系統」
請看火箭圖右下角的解決方案框框：

> **「調整參數：限制複雜度或增加正規化 (例如：改進穩定系統、增加燃料...)」**

**隨機森林 (Random Forest)** 正是那個**「改進後的穩定系統」**。
它並沒有把火箭引擎換小（它依然使用強大的決策樹作為基底），而是透過以下方式將火箭從右側的危險區，拉回中間的**「表現良好 (Good Fit)」**軌道：

* **平滑化決策 (Smoothing)**：
    單一決策樹的決策邊界通常很尖銳（像鋸齒狀），容易受極端值影響。隨機森林透過 **100 棵樹的投票**，把這些尖銳的鋸齒磨平了，讓決策邊界更圓滑。
* **容錯機制 (Fault Tolerance)**：
    如果火箭上有一個零件（一棵樹）壞掉了或判斷錯誤，其他 99 個零件（其他的樹）可以修正它。這讓火箭在升空過程中，不會因為單點故障而墜毀。

### 3. 證據：特徵重要性的變化
看回我們的實驗結果圖 (`Top 10 Key Features`)：

* **Credit Amount (貸款金額)** 與 **Age (年齡)** 躍升為最重要的特徵。

這代表火箭現在依賴的是**「穩定的結構性因素」**（借多少錢、年紀多大），而不是依賴某些奇怪的、無法解釋的微小特徵（例如單一決策樹可能過度依賴某個冷門特徵）。

**這證明了模型已經從「死記硬背」轉向了「理解通則」，成功進入了「成功入軌，穩定運行」的狀態。**