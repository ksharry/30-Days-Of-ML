# Day 08：隨機森林 (Random Forest) — 三個臭皮匠，勝過諸葛亮

昨天 Day 07 我們介紹了 **決策樹 (Decision Tree)**，它就像一位銀行經理，能畫出清楚的規則告訴我們為什麼拒貸。但我們也發現了它的致命傷：**「鑽牛角尖 (Overfitting)」**。它太容易死記硬背，導致換了新客戶就不準了。

今天我們要介紹機器學習競賽 (Kaggle) 中的長青樹、表格資料的王者：**隨機森林 (Random Forest)**。

如果不相信一個專家的判斷，那就找一百個專家來投票吧！

## 0. 歷史小百科：公牛的重量與群眾的智慧

隨機森林的核心概念——**「集成學習 (Ensemble Learning)」**，其靈感可以追溯到 1906 年的一場鄉村實驗。

英國統計學家 **法蘭西斯·高爾頓 (Francis Galton)** 參觀了普利茅斯的一個家畜展。現場舉辦了一個猜謎遊戲：讓大家猜一隻被宰殺後的公牛有多重。

現場有 **800 位參賽者**，其中有屠夫（專家），也有一般的農夫和路人（非專家）。
* **個別結果**：沒有任何一個人（包括最厲害的屠夫）猜中準確的重量 **1198 磅**。
* **集體結果**：當高爾頓把這 800 個人的猜測數字全部加起來取 **平均值** 時，神奇的事情發生了——平均數是 **1197 磅**！只差了 1 磅。

這證明了 **「群眾的智慧 (The Wisdom of Crowds)」**：許多個「略有偏差」的判斷集合起來，往往比單一專家的判斷更準確。這就是隨機森林的靈魂。

## 1. 原理：怎麼打造一座森林？

隨機森林 (Random Forest) 簡單來說，就是 **「種植 100 棵決策樹，然後讓它們投票」**。

但如果這 100 棵樹都長得一模一樣，那投出來的票也是一樣的，沒有意義。為了讓樹「不一樣」，隨機森林引入了兩個隨機機制（Bagging）：

### A. 資料隨機 (Bootstrap Sample)
假設銀行有 1000 筆客戶資料。
* **第 1 棵樹**：隨機抽 800 筆資料來學（可能重複抽到某些人）。
* **第 2 棵樹**：另外隨機抽 800 筆資料來學。
* **結果**：每棵樹看到的「世界」都略有不同，避免大家一起學壞。

### B. 特徵隨機 (Feature Randomness)
這是最關鍵的一步。在做決策（切分節點）時，決策樹通常會看所有特徵（存款、年齡、性別...）。但隨機森林強迫每一棵樹 **「只能隨機挑幾個特徵來看」**。

* 這就像 **「瞎子摸象」**：
    * **樹 A** 摸到了象鼻（只看到存款）。
    * **樹 B** 摸到了象腿（只看到年齡）。
    * **樹 C** 摸到了象耳（只看到性別）。
* 雖然單看一棵樹都不全面，但把 100 棵樹拼起來，就能還原整隻大象，而且不會被單一特徵誤導。

### C. 圖解：隨機森林的投票機制 (Voting Mechanism)

為了讓大家更直觀地理解「投票」是如何運作的，我們畫了一張示意圖：

![Random Forest Voting](https://github.com/ksharry/30-Days-Of-ML/blob/main/day8/pic/8-2.png?raw=true)

這張圖展示了一個 55 歲、貸款 5000 元、帳戶餘額高的客戶，是如何被三棵不同的樹審核的：

1.  **樹 1 (看年齡)**：因為大於 40 歲，覺得他很穩重，投 **「好人 (Good)」** 一票。
2.  **樹 2 (看金額)**：因為借款小於 8000，覺得風險可控，也投 **「好人 (Good)」** 一票。
3.  **樹 3 (看帳戶)**：這棵樹可能比較嚴格（或學到了雜訊），覺得他有風險，投了 **「壞人 (Bad)」** 一票。
4.  **最終投票**：2 票對 1 票，少數服從多數，隨機森林最終判定這位客戶是 **「好人 (Good Credit)」**。

這就是為什麼隨機森林比單一決策樹更準確的原因——它容許個別的樹犯錯，只要大部分的樹是對的就好！

---

## 2. 圖解分析：森林告訴了我們什麼？

由於我們有 100 棵樹，畫出結構圖會變成一團亂麻。取而代之的是，隨機森林給了我們一張更有商業價值的圖表：**特徵重要性 (Feature Importance)**。

![Feature Importance Chart](https://github.com/ksharry/30-Days-Of-ML/blob/main/day8/pic/8-1.jpg?raw=true)

### A. 左圖：混淆矩陣 (Confusion Matrix) — 模型的成績單

這張圖顯示了模型在測試集（共 300 筆客戶資料）上的表現。總體準確率約為 **76%** $((196+32)/300)$，這在信用風控領域是一個相當不錯的基準。

我們來拆解這四個數字背後的商業意義：

* **196 (True Good) - 成功獲利**：
    這是最開心的一群。模型預測他們會還錢，實際上他們也真的還錢了。銀行成功賺取了這 196 位客戶的利息。
* **32 (True Bad) - 成功避險**：
    這是風控的核心價值。模型準確抓出了 32 位會違約的客戶並拒絕了他們，幫銀行守住了本金。
* **13 (False Bad) - 誤殺好人**：
    模型誤以為這 13 個人很危險，但其實他們信用良好。雖然有點可惜（少賺利息），但對銀行來說，這是可以接受的「保守誤差」。
* **59 (False Good) - 潛在呆帳 (危險區)**：
    **這是我們最需要關注的數字！** 有 59 位客戶其實會違約，但模型卻誤判他們是好人而放款。這顯示隨機森林雖然強大，但在處理「偽裝成好人的壞人」時仍有改進空間（這通常需要透過調整閾值 threshold 或增加更多特徵來解決）。

### B. 右圖：特徵重要性 (Feature Importance) — 誰才是關鍵？

這張長條圖是隨機森林最有價值的部分。它告訴我們：**「在 100 棵樹的投票中，哪些特徵最常被用來區分好壞？」**

請注意這裡的排名變化（與 Day 07 的單一決策樹相比）：

1.  **Credit Amount (貸款金額) 🥇**：
    榮登第一名！這非常有趣。在單一決策樹中，這往往排在後面。但在隨機森林中，模型發現**「借多少錢」**其實是決定違約與否的最強訊號。借得越多，風險波動越大。
2.  **Age (年齡) 🥈**：
    這也是大黑馬！在單一決策樹中，年齡常被忽略。但隨機森林透過隨機特徵採樣，挖掘出了**「年齡與穩定度」**的高度相關性。年長者通常財務更穩定，違約率較低。
3.  **Checking Status (支票帳戶狀態) 🥉**：
    雖然退居第三，但依然是核心指標。現金流（Cash Flow）永遠是王道。
4.  **Duration (貸款期限)**：
    借越久，變數越多，風險越高。這與我們的直覺完全相符。

## 3. 進階實戰：參數調優 (Hyperparameter Tuning)

我們原本的隨機森林模型使用的是「預設值 (Default)」，這就像開法拉利卻只用一檔在跑。為了榨出模型的極限效能，我們使用了 **網格搜索 (GridSearchCV)** 進行了暴力測試，從多種組合中找到了最強的參數配置。

### 最佳參數組合解析

經過電腦運算，我們發現針對德國信用資料集，最強的設定是：

```python
best_params = {
    'class_weight': 'balanced',   # 是否加重壞人權重
    'max_depth': 10,              # 樹的深度限制
    'min_samples_split': 5,       # 節點再切分的最少樣本數
    'n_estimators': 100           # 樹的數量
}
```

## 4. 戰略地圖分析：隨機森林在火箭圖中的位置

讓我們再次拿出這張**「模型訓練火箭圖」**，用它來診斷我們今天的隨機森林模型。

![Rocket Strategy](https://github.com/ksharry/30-Days-Of-ML/blob/main/day2/pic/2-6.jpg?raw=true)

### 情境一：欠擬合 (Underfitting) — 推力不足，無法升空

* **圖中位置**：左側路徑。
* **現象**：火箭剛點火就掉下來了。這代表模型**「太簡單」**，連訓練集 (考古題) 都做不好。
* **在隨機森林中**：
    * 像是你只種了 1 棵樹 (`n_estimators=1`)，而且限制這棵樹只能長 1 層 (`max_depth=1`)。
    * 或者每棵樹都只能看 1 個特徵 (`max_features=1`)，導致群眾都在「瞎猜」，根本無法形成有效的決策。
* **解決方案**：**增加複雜度與規模**。增加樹的數量 (例如到 100 棵)，或是放寬樹的生長深度。

### 情境二：過擬合 (Overfitting) — 動力太強，失去控制

* **圖中位置**：右側路徑（這是 Day 07 **單一決策樹** 最常遇到的死穴）。
* **現象**：火箭飛得很快，但方向亂竄，最後炸毀。這代表模型在訓練集表現滿分 (100 分)，但在測試集 (沒看過的新客戶) 表現極差。
* **在隨機森林中**：
    * 雖然隨機森林天生比決策樹穩定，但如果樹長得**太深且沒有限制** (例如 `max_depth=None`)，每一棵樹都會變得極度敏感，把雜訊當成聖旨。
    * 就像這 100 位專家每個人都過度固執己見，雖然投票可以抵銷部分錯誤，但整體風險依然偏高。
* **解決方案**：**安裝「穩定系統」 (Stabilization)**。
    * **平滑化 (Smoothing)**：透過 100 棵樹的投票機制 (Voting)，把單一樹木尖銳的錯誤磨平。
    * **參數限制**：設定 `min_samples_leaf=5` (避免特例) 或 `max_depth=10` (限制視野)，強迫模型關注大方向而非小雜訊。

### 最終目標：表現良好 (Good Fit) — 成功入軌

## 7. 總結與比較 (Conclusion)

讓我們看看目前的最終排行榜：

| 模型 | Day | 特性 | 鐵達尼號準確率 |
| :--- | :---: | :--- | :---: |
| **邏輯回歸** | 04 | 畫直線，只求分開 | 81.00% |
| **KNN (K=17)** | 05 | 看鄰居，非線性直覺 | 81.56% |
| **SVM (Tuned)** | 06 | 高維魔法 + 參數優化 | 82.12% |
| **決策樹 (DT)** | 07 | 白箱模型，可畫圖解釋 | 74.00% |
| **隨機森林 (RF)** | **08** | **多樹投票，穩定運行** | **76.00%** |

* **在 Day 08 的實戰中**：
    * 當我們透過 `GridSearchCV` 找到了最佳參數組合（`n_estimators=100`, `class_weight='balanced'`, `max_depth=10`），我們其實就是在調整火箭的 **「推力 (樹數量)」** 與 **「導航系統 (權重與深度)」**。
    * 這樣的模型既保留了決策樹的判斷力，又消除了它的暴衝性格，最終在測試資料上達到 **穩定運行 (High Accuracy & High Recall)**，這才是我們追求的完美 AI。



**Next Day 預告：**
明天 Day 09，我們將揭曉 Kaggle 數據競賽中的絕對王者：XGBoost 與 LightGBM。 如果隨機森林是靠「多數決」的民主投票，那這兩位霸主就是靠 「從錯誤中學習」 的菁英進化。我們將學習如何利用 梯度提升 (Gradient Boosting) 技術，讓模型像爬樓梯一樣，一步步修正前一棵樹的錯誤，榨出數據的極致準確率！